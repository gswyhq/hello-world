
# 在当前目录及子目录中，的py文件中查找字符串`1234`并且忽略`.git`目录：
gswewf@gswewf-pc:~/yhb$ grep -R --include="*.py" --exclude-dir=".git" '1234' .

# 在当前目录及子目录中，的py文件中查找字符串`1234`并且忽略`.git,contexts,conf,test`目录：
gswewf@gswewf-pc:~/yhb$ grep -R --include="*.py" --exclude-dir={.git,contexts,conf,test} '123456' .

# 排除扩展名为 java 和 js 的文件
grep -E "http"  . -R --exclude=*.{java,js}

# 忽略多个隐藏目录：
gswewf@gswewf-pc:~$ grep -R --include="*.py" --exclude-dir={.cache,.local,.deepinwine,.PyCharm2016.1,.cxoffice,.PyCharm50,.git,.navicat64}  "browser" .

# 在当前目录中查找，但忽略子目录：
grep '能不能打电话' -d skip .

# 排除某些关键词的（在当前目录中搜索`semantic`，但不要有`semantics_match`）：
grep "semantic" .|grep -v "semantics_match"

# find与grep联合使用
在当前目录下的log目录中，从所有io开头的文件中查找包含有"传入参数" 或 "返回数据"的行，并输出到文件`20170823备份日志.log`中：
gswewf@gswewf-PC:~/yhb$ find log/ -name "io*"|xargs grep -e "传入参数" -e "返回数据" > 20170823备份日志.log
或：
gswewf@gswewf-PC:~/yhb$ find log/ -name "io*"|xargs grep -E "传入参数|返回数据" > 20170823备份日志.log

# 使用 -l 选项可以只显示文件名：
gswewf@gswewf-PC:~/output$ grep -l "http" *.json

# 查询06.10、06.11、06.12三天的日志：
remote_cmd="grep -e '2018-06-10' -e '2018-06-11' -e '2018-06-12' /home/ubuntu/bnrs/log/io.log* | grep '返回数据' > /home/ubuntu/bnrs/log/bnrs_dump_bak.log"
# 或者：
remote_cmd="grep -E '2018-06-10|2018-06-11|2018-06-12' /home/ubuntu/bnrs/log/io.log* | grep '返回数据' > /home/ubuntu/bnrs/log/bnrs_dump_bak.log"

# 查询6月10日除10、11、12点之外的日志：
remote_cmd="grep '2018-06-10' /home/ubuntu/bnrs/log/io.log*| grep -v '2018-06-09 10:' | grep -v '2018-06-09 11:' | grep -v '2018-06-09 12:' | grep '返回数据' > /home/ubuntu/bnrs/log/bnrs_dump_bak.log"
# 或者：
remote_cmd="grep '2018-06-10' /home/ubuntu/bnrs/log/io.log*| grep -v -e '2018-06-09 10:' -e '2018-06-09 11:' -e '2018-06-09 12:' | grep '返回数据' > /home/ubuntu/bnrs/log/bnrs_dump_bak.log"
# 或者：
remote_cmd="grep '2018-06-10' /home/ubuntu/bnrs/log/io.log*| grep -vE '2018-06-09 10:|2018-06-09 11:|2018-06-09 12:' | grep '返回数据' > /home/ubuntu/bnrs/log/bnrs_dump_bak.log"

# 使用grep查找文件中指定字符出现的次数
grep -o '好' 文件名.txt | wc -l

-o 指示grep显示所有匹配的地方，并且每一个匹配单独一行输出。这样只要统计输出的行数就可以知道这个字符出现的次数了。

