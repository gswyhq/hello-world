
docker 容器启动不了，报错：
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]

解决方法，在宿主机上运行下命令即可：
zy@ubuntu:~/docker/elasticsearch$ sudo sysctl -w vm.max_map_count=262144


Elasticsearch 网络设置
network.host
节点将绑定到一个主机名或者 ip 地址并且会将该这个节点通知集群中的其他节点。接受 ip 地址，主机名，指定值或者包含这些值的数组
默认值：local
discovery.zen.ping.unicast.hosts
为了加入集群，一个节点至少需要知道集群中其他节点的主机名或者 ip 地址。这个设置提供初始其他节点列表，当前节点将尝试联系。接收 ip 地址或者主机名。
默认值：["127.0.0.1", "[::1]"]
http.port
HTTP 请求通信端口。接收单值或者一个范围。如果指定一个范围，该节点将会绑定范围的第一个可用顶点。
默认值：9200-9300
transport.tcp.port
节点间通信端口。接收单值或者一个范围。如果指定一个范围，该节点将会绑定范围的第一个可用顶点。
默认值：9300-9400

network.host 的特殊值
以下特殊值将可以传递给 network.host：

[networkInterface] 网络接口的地址，例如 en0。
local 系统中的回路地址，例如 127.0.0.1。
site 系统中任何的本地站点地址，例如 192.168.0.1。
global 系统中的任何全局作用域地 8.8.8.8。
IPv4 vs IPv6

默认情况下这些特殊值都可以在 IPv4 和IPv6 中使用，但是你可以使用 :ipv4，:ipv6 字符限制使用。例如，en0:ipv4 将绑定 en0 接口的 IPv4 地址。
Tip：在云上使用，更多特别设定可用，当你在 AWS 云或者 Google Compute Engine 云上使用时

高级网络配置
在常用的网络配置中解释的 network.host 是快捷方式，同时设置绑定地址和发布地址。在高级使用情况下，例如在一个代理服务器中运行，你可能需要设置如下不同的值：
network.bind_host
这将指定用于监听请求的网络接口。一个节点可以绑定多个接口，例如有两块网卡，一个本地站点地址，一个本地地址。
默认值：network.host
network.publish_host
发布地址，一个单一地址，用于通知集群中的其他节点，以便其他的节点能够和它通信。当前，一个 elasticsearch 节点可能被绑定到多个地址，但是仅仅有一个发布地址。如果没有指定，这个默认值将为 network.host 配置中的最好地址，以 IPv4/Ipv6 堆栈性能，之后以稳定性排序。
上述两个设置可以向 network.host 那样被设置--他们都接受 IP 地址，主机名和特定值

高级 TCP 设置
任何使用 TCP（像 HTTP 和 Transport 模块）共享如下设置：

network.tcp.no_delay 开启或关闭 TCP 无延迟设置。默认值为 true。
network.tcp.keep_alive 开启或关闭 TCP 长连接，默认值为 true。
network.tcp.reuse_address 一个地址是否可以被重用。在非 windows 机子上默认值为 true。
network.tcp.send_buffer_size TCP 发送缓冲区大小（以size unit指定）。没有默认值。
network.tcp.receive_buffer_size TCP 接收缓冲区大小（以size unit指定）。没有默认值。
Transport 和 HTTP 协议
一个Elasticsearch节点暴露两个网络协议配置继承上面的设置，但可独立地进一步配置两个网络协议：
TCP Transport
用于集群中节点之间的通信。
HTTP
暴露基于 HTTP JSON 请求接口，被所有客户端使用，比局限于 Java 客户端。

network.bind_host: 192.168.0.1
设置绑定的ip地址，默认情况下，ElasticSearch使用0.0.0.0地址，并为http传输开启9200-9300端口，
为节点到节点的通信开启9300-9400端口，也可以自行设置IP地址：，绑定这台机器的任何一个ip。

network.publish_host: 192.168.0.1
设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。

network.host: 192.168.0.1
这个参数是用来同时设置bind_host和publish_host上面两个参数。

有时候报错：
Caused by: while scanning a simple key
 in 'reader', line 9, column 1:
    discovery.zen.minimum_master_nodes:2
    ^
could not find expected ':'
 in 'reader', line 11, column 1:
    discovery.zen.ping.multicast.ena ...
    ^
解决方案：
参数冒号后加空格,或者是数组中间加空格
例如:
# discovery.zen.minimum_master_nodes: 3

有时候报错：
[2018-03-02T01:46:36,072][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [master] uncaught exception in thread [main]
org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.multicast.enabled] please check that any required plugins are installed, or check the breaking changes documentation for removed settings

解决方案：
es1.0 版本的集群的discovery默认采用的是组播（multicast）模式，但是在es2.2版本中已去除该模式，虽然提供了multicast的插件，但是官方说不建议采用multicast的模式，故我们只能采用单播(unicast)模式。
删除`elasticsearch.yml`文件中如下的配置即可
# 禁止当前节点发现多个集群节点，默认值为true：
# 这个设置把组播的自动发现给关闭了，为了防止其他机器上的节点自动连入。
discovery.zen.ping.multicast.enabled: false

有时候报错：
org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: unknown setting [discovery.zen.ping.timeout] did you mean any of [discovery.zen.ping_timeout, discovery.zen.fd.ping_timeout, discovery.zen.join_timeout, discovery.zen.publish_timeout, discovery.zen.commit_timeout]?
`elasticsearch.yml`文件中如下的配置
discovery.zen.ping.timeout: 120s
改为：
discovery.zen.ping_timeout: 120s

有时候报错：
org.elasticsearch.cluster.block.ClusterBlockException: blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];\n
`elasticsearch.yml`文件中如下的配置
network.host: 0.0.0.0
http.port: 9200

# 一次请求超过一万条记录时候，会报错：
Result window is too large, from + size must be less than or equal to: [10000] but was [30000].
ES默认的分页机制一个不足的地方是，比如有5010条数据，当你仅想取第5000到5010条数据的时候，ES也会将前5000条数据加载到内存当中，所以ES为了避免用户的过大分页请求造成ES服务所在机器内存溢出，默认对深度分页的条数进行了限制，默认的最大条数是10000条，这是正是问题描述中当获取第10000条数据的时候报Result window is too large异常的原因。
要解决这个问题，可以使用下面的方式来改变ES默认深度分页的index.max_result_window 最大窗口值
curl -XPUT http://127.0.0.1:9200/my_index/_settings -d '{ "index" : { "max_result_window" : 500000}}'
其中my_index为要修改的index名，500000为要调整的新的窗口数。将该窗口调整后，便可以解决无法获取到10000条后数据的问题。
注意事项
通过上述的方式解决了我们的问题，但也引入了另一个需要我们注意的问题，窗口值调大了后，虽然请求到分页的数据条数更多了，但它是用牺牲更多的服务器的内存、CPU资源来换取的。