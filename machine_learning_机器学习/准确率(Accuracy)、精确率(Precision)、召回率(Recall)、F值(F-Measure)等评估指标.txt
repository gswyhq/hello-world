

混淆矩阵
True Positive(真正，TP)：将正类预测为正类数
True Negative(真负，TN)：将负类预测为负类数
False Positive(假正，FP)：将负类预测为正类数误报 (Type I error)
False Negative(假负，FN)：将正类预测为负类数→漏报 (Type II error)

                      预测列表
              YES             NO              总计
实际   YES     TP              FN              P(实际为YES)
类别   NO      FP              TN              N(实际为NO)
      总计     P'(被分为YES)    N'(被分为NO)     P+N

1、准确率（Accuracy）
准确率(accuracy)计算公式为：acc = (真正+真负)/(真正+真负+假真+假负) = (TP+TN)/(TP+TN+FP+FN)

注：准确率是我们最常见的评价指标，而且很容易理解，就是被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好。
准确率确实是一个很好很直观的评价指标，但是有时候准确率高并不能代表一个算法就好。比如某个地区某天地震的预测，假设我们有一堆的特征作为地震分类的属性，类别只有两个：0：不发生地震、1：发生地震。
一个不加思考的分类器，对每一个测试用例都将类别划分为0，那那么它就可能达到99%的准确率，但真的地震来临时，这个分类器毫无察觉，这个分类带来的损失是巨大的。
为什么99%的准确率的分类器却不是我们想要的，因为这里数据分布不均衡，类别1的数据太少，完全错分类别1依然可以达到很高的准确率却忽视了我们关注的东西。
因此，单纯靠准确率来评价一个算法模型是远远不够科学全面的。

2、错误率（Error rate）
错误率则与准确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(TP+TN+FP+FN)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 - error rate。

3、灵敏度（sensitive）
sensitive = (真正)/(真正+假负) = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。

4、特效度（sensitive）
specificity = (真负)/(真负+假正) = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。

5、精确率、精度（Precision）
精确率(precision rate)是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。
那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是精确率；
精确率(precision) = (真正)/(真正+假正) = TP /(TP + FP)

6、召回率(recall rate)是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。
那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。
召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitive，可以看到召回率与灵敏度是一样的。

在信息检索领域，精确率和召回率又被称为查准率和查全率，
查准率＝检索出的相关信息量 / 检索出的信息总量
查全率＝检索出的相关信息量 / 系统中的相关信息总量

7、综合评价指标（F-Measure）
P(精确率)和R(召回率)指标有时候会出现的矛盾的情况，这样就需要综合考虑他们，最常见的方法就是F-Measure（又称为F-Score）。
F-Measure是Precision和Recall加权调和平均：
         (α×α+1) × P × R
F = ─────────────────────────
             α×α×(P+R)

当参数α=1时，就是最常见的F1，也即
         2 × P × R
F1 = ──────────────────
           P+R

可知F1综合了P和R的结果，当F1较高时则能说明试验方法比较有效。

一般来说，准确率和召回率反映了分类器性能的两个方面，单一依靠某个指标并不能较为全面地评价一个分类器的性能。
假如分类器只将苹果特征十分明显、是苹果的概率非常高的样本分为苹果，其余的样本分为非苹果，此时该分类器的准确率就会非常的高，但是它因为将所有疑似苹果都错误分为非苹果，召回率变得非常低。
假如分类器将所有可能为苹果的样本全部划分为苹果，其余的样本为非苹果，此时该分类器的召回率会非常之高，但是它因为将所有可能为苹果的样本分为苹果时引入了许多错误，准确率不可能高。
引入F1-Score作为综合指标，就是为了平衡准确率和召回率的影响，较为全面地评价一个分类器。
有时候考虑到不同的需求，可能会更看重准确率或者召回率。
这时我们可以引入F2-Score和F0.5-Score。包括F1-Score，这三个指标都来自以下定义，只是参数不同。

      (1 + β × β) × P × R
Fβ = ──────────────────────
       (β × β) × P + R

其中，F1-Score是指准确率和召回率一样重要；

F2-Score是指召回率比准确率重要一倍；
F0.5-Score是指准确率比召回率重要一倍。


8、其他评价指标
计算速度：分类器训练和预测需要的时间；
鲁棒性：处理缺失值和异常值的能力；
可扩展性：处理大数据集的能力；
可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。

8.1、ROC曲线：
ROC（Receiver Operating Characteristic）曲线是以假正率（FP_rate）和真正率（TP_rate）为轴的曲线，ROC曲线下面的面积我们叫做AUC；
TPR，真阳率(True Positive Rate)等于真阳数量除以实际阳性(真阳加假阴), 也称查出率=实际查出数/最大可能查出数即所有阳性；TPR就是召回率(Recall)，两者是一样的。
FPR，假阳率(False Positive Rate)等于假阳数量除以实际阴性(假阳加真阴), 也称误检率=实际误检数/最大可能误检数即所有阴性；
                 TP
TPR(查出率) = ──────────────────
               TP + FN
                 FP
FPR(误检率) = ──────────────────
               FP + TN

8.2、PR曲线：
Precision-Recall曲线顾名思义即Precision为纵轴，Recall为横轴的曲线。即，PR（Precision-Recall）曲线。
精确率(precision) = (真正)/(真正+假正) = TP /(TP + FP)
在正负样本分布得极不均匀(highly skewed datasets)，负例远大于正例时，并且这正是该问题正常的样本分布时，PRC比ROC能更有效地反应分类器的好坏，即PRC曲线在正负样本比例悬殊较大时更能反映分类的真实性能。正负样本比例为1:10，有可能ROC效果依然看似很好，但是PR曲线则表现的比较差。
举例来说，混淆矩阵Confusion Matrix:
[[21914  1524]
 [  472   294]]
tn, fp, fn, tp = 21914, 1524, 472, 294
实际阳性客户总量：766=472+294
检出阳性客户量：1818=1524+294
检出正确阳性客户量：294
漏检阳性客户量：472
误检阳性客户量：1524
分类器将1818 (1524+294)个样本预测为positive，而其中实际上只有294个是真正的positive。 我们凭直觉来看，其实这个分类器并不好。但由于真正negative 样本的数量远远大于positive，ROC的结果却“看上去很美”，因为这时FPR因为负例基数大的缘故依然很小。所以，在这种情况下，PRC更能体现本质。
之所以出现上面分析到的两者差异，是因为FPR 和 TPR (Recall) 只与真实的正例或负例中的一个相关，而其他指标如Precision则同时与真实的正例与负例都有关。

二.举个栗子
假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标。

TP: 将正类预测为正类数 40
FN: 将正类预测为负类数 20
FP: 将负类预测为正类数 10
TN: 将负类预测为负类数 30

准确率(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 70%
精确率(precision) = TP/(TP+FP) = 80%
召回率(recall) = TP/(TP+FN) = 2/3

一般评分以F1-score为准，得分相同时，参照accuracy排序。
参考：https://blog.csdn.net/dzzzzzzzzzz/article/details/83316271
https://dc.cloud.alipay.com/index#/topic/data?id=8

